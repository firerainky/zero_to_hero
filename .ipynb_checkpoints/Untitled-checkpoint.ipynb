{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9487dcc-6c63-4941-8ab8-9a8fb366155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc019ce-2eca-43a7-970c-df84ced0399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b343bf80-523c-4d99-9ea5-875450c32ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea7df6a-d94d-483a-b3ec-2200ade28851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882610fa-e825-4453-bedb-31ef77062707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d2d3138-256b-45fe-8817-058714a60029",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words[:10]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6401204-0826-4efa-8414-673d352637e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339919b9-27a1-4726-8844-5cb32f67decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        N[stoi[ch1], stoi[ch2]] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4286c88-6967-4022-9efa-8f781fdd88e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922eed72-2425-4c92-967f-fb0d6c889f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p / p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b43705a-c0e5-41c0-9c90-7a554ac3d76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a40f8e08-f649-44d7-adc8-acfe3be11b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze\n",
      "momasurailezitynn\n",
      "konimittain\n",
      "llayn\n",
      "ka\n",
      "da\n",
      "staiyaubrtthrigotai\n",
      "moliellavo\n",
      "ke\n",
      "teda\n",
      "ka\n",
      "emimmsade\n",
      "enkaviyny\n",
      "ftlspihinivenvorhlasu\n",
      "dsor\n",
      "br\n",
      "jol\n",
      "pen\n",
      "aisan\n",
      "ja\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = N / N.sum(1, keepdim = True)\n",
    "for _ in range(20):\n",
    "    w = []\n",
    "    cur_idx = 0\n",
    "    while True:\n",
    "        char_idx = torch.multinomial(p[cur_idx], num_samples = 1, replacement = True, generator = g).item()\n",
    "        char = itos[char_idx]\n",
    "        if (char == '.'):\n",
    "            break\n",
    "        else:\n",
    "            w += char\n",
    "            cur_idx = char_idx\n",
    "    word = ''.join(w)\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b160b22-ae15-4944-a914-fb637d79f741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".e, prob=0.0478, logprob=-3.0408\n",
      "em, prob=0.0377, logprob=-3.2793\n",
      "mm, prob=0.0253, logprob=-3.6772\n",
      "ma, prob=0.3899, logprob=-0.9418\n",
      "a., prob=0.1960, logprob=-1.6299\n",
      ".o, prob=0.0123, logprob=-4.3982\n",
      "ol, prob=0.0780, logprob=-2.5508\n",
      "li, prob=0.1777, logprob=-1.7278\n",
      "iv, prob=0.0152, logprob=-4.1867\n",
      "vi, prob=0.3541, logprob=-1.0383\n",
      "ia, prob=0.1381, logprob=-1.9796\n",
      "a., prob=0.1960, logprob=-1.6299\n",
      ".a, prob=0.1377, logprob=-1.9829\n",
      "av, prob=0.0246, logprob=-3.7045\n",
      "va, prob=0.2495, logprob=-1.3882\n",
      "a., prob=0.1960, logprob=-1.6299\n",
      "log_likelihood=tensor(-38.7856)\n",
      "nll=tensor(38.7856)\n",
      "average_nll=tensor(2.4241)\n"
     ]
    }
   ],
   "source": [
    "# 接下来来看我们要如何找到一个 loss function, 首先查看我们 training set 中的概率函数是什么样的\n",
    "P = N.float()\n",
    "P /= P.sum(1, keepdim = True)\n",
    "# P 是我们的概率矩阵\n",
    "# 接下来我们来计算一下训练集中前三个名字的概率情况是啥样的\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for word in words[:3]:\n",
    "    chs = ['.'] + list(word) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        prob = P[stoi[ch1], stoi[ch2]]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        print(f'{ch1}{ch2}, prob={prob:.4f}, logprob={logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "average_nll = nll / n\n",
    "print(f'{average_nll=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938f10af-33a2-407f-8e81-e57f22b77e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有了判断一个生成好不好的函数之后，接下来做什么呢？\n",
    "# create the training set of all the bigrams, 也就是创建训练集\n",
    "xs = []\n",
    "ys = []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3de30ad-f215-4010-96e1-370321422c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0485a18-9b7b-48f4-8217-2a3e7c85c249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e62bff-8198-4301-a991-85dde0402203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但是这样的 xs 和 ys 并不能直接作为训练内容输入给 neural network\n",
    "# 我们需要把他们转变成神经网络需要的 tensor, 为什么这个直给不行我暂时还没有答案\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489f885f-022b-4c24-8756-872d20f106b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d08b75e-2bd2-41e0-a43c-48ebdbc35aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb77b72-51d9-4831-93e9-573c9cb494a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07e23847-5386-4088-a4e4-52e5a26f817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13d0453d-1a7b-4804-9475-9c1265c8692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1287,  1.1939,  0.8793,  0.7865, -0.3958, -0.1270,  1.0221, -0.2848,\n",
       "          0.0275,  0.0395, -0.2126,  1.2415,  0.1728, -0.8247,  0.8452,  1.0366,\n",
       "         -1.3000, -0.9311, -1.0840, -0.6212,  0.8821, -0.5319, -1.2309,  0.0333,\n",
       "         -0.7589, -1.7089, -0.2693],\n",
       "        [ 0.5425, -2.4221, -0.7431, -0.1400, -1.2746, -0.7344, -0.1106,  0.0065,\n",
       "          1.2588, -0.7844,  0.9122, -0.2936,  0.0866, -0.8417, -0.0550, -0.7908,\n",
       "          0.2158,  1.4122,  0.6763,  0.8235,  1.2779,  0.1169, -1.2553, -0.9245,\n",
       "         -1.4058,  0.1089, -0.1254],\n",
       "        [-0.3672,  1.2942, -0.3825, -1.0628,  0.6344, -1.0065,  0.9576,  1.8458,\n",
       "          0.1845,  0.6256, -1.4484, -0.4960, -0.8647, -0.1973, -0.6178,  1.1137,\n",
       "         -1.0322, -0.5128,  1.1510, -0.0975,  0.2041,  0.4450,  0.4166, -0.6610,\n",
       "          1.7890,  1.0346, -1.5296],\n",
       "        [-0.3672,  1.2942, -0.3825, -1.0628,  0.6344, -1.0065,  0.9576,  1.8458,\n",
       "          0.1845,  0.6256, -1.4484, -0.4960, -0.8647, -0.1973, -0.6178,  1.1137,\n",
       "         -1.0322, -0.5128,  1.1510, -0.0975,  0.2041,  0.4450,  0.4166, -0.6610,\n",
       "          1.7890,  1.0346, -1.5296],\n",
       "        [-0.0094, -0.4546,  0.1698, -0.8301, -0.4807,  1.9825, -2.4131,  2.4903,\n",
       "          1.5202, -0.3947,  0.7845,  1.7053, -0.1990,  0.8188,  0.3719,  1.3670,\n",
       "         -0.8598, -1.3807,  2.2715,  0.3419, -0.8787,  1.1921, -0.4387,  1.7152,\n",
       "         -1.0465, -2.0955,  0.2735]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27))\n",
    "xenc @ W # ((5, 27) @ (27, 27)) = (5, 27), 27 neurons, @ - dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d09b0775-fbe6-4640-9dfa-b35ec036df8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1973,  0.0000,  0.0000,\n",
       "        -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "        -0.0000, -0.0000, -0.0000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc[3] * W[:, 13] # 响应的, * - element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4707b7d1-dca6-4b1d-a856-b41b6614d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1973)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc[3] * W[:, 13]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "761833e0-51f1-4d87-9288-b62abffbbe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1973)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc @ W)[3, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e1718adf-9ad8-43e0-8ae4-c77a3761fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们回到构建 neural network 来吧\n",
    "# randomly initialize 27 neuron's weights, each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ddad31e9-392e-4209-91a9-e8636015ba85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xs 是 neural network 的 input, 下面的就是 neural network 的 forward pass\n",
    "xenc = F.one_hot(xs, num_classes = 27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N \n",
    "probs = counts / counts.sum(1, keepdim = True) # probabilities to next character, normalize\n",
    "# btw: the last 2 lines here are togather called a \"softmax\"\n",
    "probs.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a890588b-f54a-4634-b733-fa3033f7bd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "d558a8d9-85d7-4a6d-8c14-fd3411fb118d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0123),\n",
       " tensor(0.0181),\n",
       " tensor(0.0267),\n",
       " tensor(0.0737),\n",
       " tensor(0.0150))"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, 5], probs[1, 13], probs[2, 13], probs[3, 1], probs[4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4ad90bad-8ec3-44d1-b919-941dfac2eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7693)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(5), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e5e754-74ac-4df4-a3a4-44bc1da0488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chars = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator = g, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0ce8f6c-fdb6-42e1-b74d-1a453f24cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.696505546569824\n",
      "2.6773722171783447\n",
      "2.6608052253723145\n",
      "2.6463515758514404\n",
      "2.633665084838867\n",
      "2.622471570968628\n",
      "2.6125476360321045\n",
      "2.6037068367004395\n",
      "2.595794916152954\n",
      "2.5886809825897217\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(10):\n",
    "    # xs 是 neural network 的 input, 下面的就是 neural network 的 forward pass\n",
    "    xenc = F.one_hot(xs, num_classes = 27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N \n",
    "    probs = counts / counts.sum(1, keepdims = True) # probabilities to next character, normalize\n",
    "    # btw: the last 2 lines here are togather called a \"softmax\"\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b41360a-cbdc-4435-9a0b-c93138fe3af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'uuid' has no attribute 'uuid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m uuids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid\u001b[49m()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m uuids:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'uuid' has no attribute 'uuid'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "uuids = [str(uuid.uuid4()) for _ in range(20)]\n",
    "\n",
    "for u in uuids:\n",
    "    print(u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
